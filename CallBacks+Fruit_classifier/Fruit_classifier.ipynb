{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Our Fruit Classifier\n",
    "\n",
    "#### Experimenting with Callbacks\n",
    "\n",
    "- let's create our data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 41322 images belonging to 81 classes.\n",
      "Found 13877 images belonging to 81 classes.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.layers import Dense,Dropout,Activation,Flatten,Conv2D,MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "import os\n",
    "\n",
    "num_classes = 81\n",
    "img_rows,img_cols = 32,32\n",
    "batch_size = 16\n",
    "\n",
    "train_data_dir = 'D:/major1proj1/CallBacks+Fruit_classifier/fruits-360/train'\n",
    "validation_data_dir = './fruits-360/validation'\n",
    "\n",
    "#Let's use some data augmentation\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,rotation_range=30,\n",
    "                                  width_shift_range = 0.3,\n",
    "                                  height_shift_range = 0.3,\n",
    "                                  horizontal_flip = True,\n",
    "                                  fill_mode = 'nearest')\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_data_dir,\n",
    "                                                   target_size=(img_rows,img_cols),\n",
    "                                                   batch_size = batch_size,\n",
    "                                                   class_mode='categorical',\n",
    "                                                   shuffle=True)\n",
    "validation_generator = validation_datagen.flow_from_directory(validation_data_dir,\n",
    "                                                             target_size=(img_rows,img_cols),\n",
    "                                                             batch_size = batch_size,\n",
    "                                                             class_mode = 'categorical',\n",
    "                                                             shuffle = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's define our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 13, 13, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 11, 11, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               819712    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 81)                41553     \n",
      "=================================================================\n",
      "Total params: 926,833\n",
      "Trainable params: 926,833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32,kernel_size = (3,3),padding = 'same',activation='relu',input_shape = (img_rows,img_cols,3)))\n",
    "model.add(Conv2D(32,kernel_size = (3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(num_classes,activation='softmax'))\n",
    "\n",
    "\n",
    "# initiate RMSprop optimizer and configure some parameters\n",
    "#opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "print(model.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2582/2582 [==============================] - 1182s 456ms/step - loss: 3.5822 - accuracy: 0.0955 - val_loss: 1.6669 - val_accuracy: 0.4482\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.66688, saving model to fruits_fresh_cnn.h5\n",
      "Epoch 2/10\n",
      "2582/2582 [==============================] - 662s 256ms/step - loss: 1.7454 - accuracy: 0.4395 - val_loss: 0.6462 - val_accuracy: 0.8103\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.66688 to 0.64621, saving model to fruits_fresh_cnn.h5\n",
      "Epoch 3/10\n",
      "2582/2582 [==============================] - 261s 101ms/step - loss: 1.0181 - accuracy: 0.6641 - val_loss: 0.4595 - val_accuracy: 0.8501\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.64621 to 0.45946, saving model to fruits_fresh_cnn.h5\n",
      "Epoch 4/10\n",
      "2582/2582 [==============================] - 116s 45ms/step - loss: 0.7325 - accuracy: 0.7551 - val_loss: 0.2530 - val_accuracy: 0.9193\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.45946 to 0.25303, saving model to fruits_fresh_cnn.h5\n",
      "Epoch 5/10\n",
      "2582/2582 [==============================] - 96s 37ms/step - loss: 0.5730 - accuracy: 0.8043 - val_loss: 0.2302 - val_accuracy: 0.9226\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.25303 to 0.23022, saving model to fruits_fresh_cnn.h5\n",
      "Epoch 6/10\n",
      "2582/2582 [==============================] - 484s 188ms/step - loss: 0.4863 - accuracy: 0.8358 - val_loss: 0.2130 - val_accuracy: 0.9216\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.23022 to 0.21300, saving model to fruits_fresh_cnn.h5\n",
      "Epoch 7/10\n",
      "2582/2582 [==============================] - 868s 336ms/step - loss: 0.4244 - accuracy: 0.8538 - val_loss: 0.1740 - val_accuracy: 0.9314\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.21300 to 0.17402, saving model to fruits_fresh_cnn.h5\n",
      "Epoch 8/10\n",
      "2582/2582 [==============================] - 967s 375ms/step - loss: 0.3741 - accuracy: 0.8731 - val_loss: 0.2250 - val_accuracy: 0.9124\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.17402\n",
      "Epoch 9/10\n",
      "2582/2582 [==============================] - 684s 265ms/step - loss: 0.3474 - accuracy: 0.8813 - val_loss: 0.1519 - val_accuracy: 0.9529\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.17402 to 0.15186, saving model to fruits_fresh_cnn.h5\n",
      "Epoch 10/10\n",
      "2582/2582 [==============================] - 122s 47ms/step - loss: 0.3191 - accuracy: 0.8874 - val_loss: 0.1177 - val_accuracy: 0.9521a\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.15186 to 0.11772, saving model to fruits_fresh_cnn.h5\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import RMSprop, SGD\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping,ReduceLROnPlateau\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"fruits_fresh_cnn.h5\",monitor = 'val_loss',\n",
    "                            mode = 'min',save_best_only=True,\n",
    "                            verbose = 1)\n",
    "\n",
    "earlystop = EarlyStopping(monitor = 'val_loss',min_delta=0,patience=3,\n",
    "                         verbose = 1, restore_best_weights = True)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss',factor = 0.2,\n",
    "                             patience = 3, verbose = 1, min_delta = 0.0001)\n",
    "\n",
    "#min_delta = It is the absolute value and is the minimum change reqiured before we stop\n",
    "# monitor = value being monitored for improvement\n",
    "# patiennce = No. of epochs we wait before stopping\n",
    "#restore_best_weights = keeps the best weight once stopped\n",
    "\n",
    "# we put our call backs into the call back list\n",
    "callbacks = [earlystop,checkpoint,reduce_lr]\n",
    "\n",
    "#we use very small learning rate\n",
    "model.compile(loss = 'categorical_crossentropy',optimizer = RMSprop(lr=0.0001),\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "nb_train_samples = 41322\n",
    "nb_validation_samples = 13877\n",
    "epochs = 10\n",
    "\n",
    "history = model.fit(train_generator,\n",
    "                   steps_per_epoch = nb_train_samples//batch_size,\n",
    "                   epochs = epochs,\n",
    "                   callbacks = callbacks,\n",
    "                   validation_data = validation_generator,\n",
    "                   validation_steps = nb_validation_samples//batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### saving history file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickling \n",
    "import pickle\n",
    "\n",
    "pickle_out = open(\"fruit_classifier.pickle\",\"wb\")\n",
    "pickle.dump(history.history,pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [2.9589972496032715, 1.502876877784729, 0.9288855791091919, 0.6888878345489502, 0.5482609272003174, 0.46992334723472595, 0.4071016311645508, 0.36432820558547974, 0.3325129449367523, 0.3070043921470642], 'accuracy': [0.17731080949306488, 0.5134121179580688, 0.6924417614936829, 0.7681692838668823, 0.8140463829040527, 0.8401200771331787, 0.8591488003730774, 0.8743523955345154, 0.8857793211936951, 0.8918316960334778], 'val_loss': [1.6668760776519775, 0.646206259727478, 0.4594568908214569, 0.25302544236183167, 0.23021800816059113, 0.21300257742404938, 0.1740199476480484, 0.22502288222312927, 0.15186411142349243, 0.117721326649189], 'val_accuracy': [0.44824105501174927, 0.810265302658081, 0.8501297831535339, 0.9192618131637573, 0.9226499199867249, 0.9216406941413879, 0.9313725233078003, 0.912413477897644, 0.952926754951477, 0.9520617127418518], 'lr': [1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-04]}\n"
     ]
    }
   ],
   "source": [
    "pickle_in = open(\"fruit_classifier.pickle\",\"rb\")\n",
    "saved_history = pickle.load(pickle_in)\n",
    "print(saved_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion_matrix\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Singleton array 0 cannot be considered a valid collection.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-a251118ca9e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Confusion_matrix\\n\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mcnf_matrix\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcnf_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cv\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m     \"\"\"\n\u001b[1;32m--> 276\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    277\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is not supported\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cv\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m     \"\"\"\n\u001b[1;32m---> 81\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    250\u001b[0m     \"\"\"\n\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m     \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    253\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    250\u001b[0m     \"\"\"\n\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m     \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    253\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_num_samples\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    193\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'shape'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 195\u001b[1;33m             raise TypeError(\"Singleton array %r cannot be considered\"\n\u001b[0m\u001b[0;32m    196\u001b[0m                             \" a valid collection.\" % x)\n\u001b[0;32m    197\u001b[0m         \u001b[1;31m# Check that shape is returning an integer or default to len\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Singleton array 0 cannot be considered a valid collection."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import numpy as np\n",
    "from keras.models import load_model \n",
    "\n",
    "img_rows,img_height,img_depth = 28,28,3\n",
    "model = load_model(\"fruits_fresh_cnn.h5\")\n",
    "\n",
    "class_labels = validation_generator.class_indices\n",
    "class_labels = {v: k for k, v in class_labels.items()}\n",
    "classes = list(class_labels.values())\n",
    "\n",
    "nb_train_samples = 41322\n",
    "nb_validation_samples = 13877\n",
    "\n",
    "#Confusion matrix and classification report\n",
    "y_pred = model.predict_generator(validation_generator, nb_validation_samples // batch_size+1)\n",
    "y_pred = np.argmax(y_pred,axis=1)\n",
    "\n",
    "print('Confusion_matrix\\n\\n')\n",
    "\n",
    "cnf_matrix =confusion_matrix(validation_generator.classes, y_pred)\n",
    "print(cnf_matrix)\n",
    "\n",
    "#plotting\n",
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "plt.imshow(cnf_matrix,interpolation='nearest')\n",
    "\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(classes))\n",
    "_ = plt.xticks(tick_marks, classes, rotation=90)\n",
    "_ = plt.yticks(tick_marks, classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displying our confusion matrrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion_matrix\n",
      "\n",
      "\n",
      "[[121   0   0 ...   0   0   0]\n",
      " [  0 163   0 ...   0   0   0]\n",
      " [  0   0 132 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ... 164   0   0]\n",
      " [  0   0   0 ...   0 127   0]\n",
      " [  0   0   0 ...   0   0 249]]\n",
      "classification_report\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "     Apple Braeburn       0.75      0.74      0.74       164\n",
      "     Apple Golden 1       0.95      0.99      0.97       164\n",
      "     Apple Golden 2       0.96      0.80      0.88       164\n",
      "     Apple Golden 3       0.69      1.00      0.81       161\n",
      " Apple Granny Smith       0.94      1.00      0.97       164\n",
      "        Apple Red 1       0.82      1.00      0.90       164\n",
      "        Apple Red 2       1.00      1.00      1.00       164\n",
      "        Apple Red 3       1.00      0.85      0.92       144\n",
      "Apple Red Delicious       1.00      1.00      1.00       166\n",
      "   Apple Red Yellow       0.97      1.00      0.98       164\n",
      "            Apricot       1.00      1.00      1.00       164\n",
      "            Avocado       1.00      1.00      1.00       143\n",
      "       Avocado ripe       1.00      1.00      1.00       166\n",
      "             Banana       0.91      1.00      0.95       166\n",
      "         Banana Red       0.86      0.98      0.91       166\n",
      "       Cactus fruit       0.98      0.90      0.94       166\n",
      "       Cantaloupe 1       1.00      1.00      1.00       164\n",
      "       Cantaloupe 2       0.83      0.99      0.91       164\n",
      "          Carambula       0.88      0.90      0.89       166\n",
      "           Cherry 1       0.66      0.97      0.79       164\n",
      "           Cherry 2       0.97      0.67      0.79       246\n",
      "     Cherry Rainier       1.00      0.83      0.91       246\n",
      "   Cherry Wax Black       0.98      1.00      0.99       164\n",
      "     Cherry Wax Red       1.00      1.00      1.00       164\n",
      "  Cherry Wax Yellow       1.00      1.00      1.00       164\n",
      "         Clementine       1.00      1.00      1.00       166\n",
      "              Cocos       1.00      1.00      1.00       166\n",
      "              Dates       1.00      1.00      1.00       166\n",
      "         Granadilla       1.00      1.00      1.00       166\n",
      "         Grape Pink       0.88      1.00      0.94       164\n",
      "        Grape White       1.00      1.00      1.00       166\n",
      "      Grape White 2       1.00      1.00      1.00       166\n",
      "    Grapefruit Pink       1.00      1.00      1.00       166\n",
      "   Grapefruit White       0.81      1.00      0.90       164\n",
      "              Guava       1.00      1.00      1.00       166\n",
      "        Huckleberry       1.00      1.00      1.00       166\n",
      "               Kaki       1.00      1.00      1.00       166\n",
      "               Kiwi       1.00      1.00      1.00       156\n",
      "           Kumquats       1.00      1.00      1.00       166\n",
      "              Lemon       1.00      0.77      0.87       164\n",
      "        Lemon Meyer       1.00      1.00      1.00       166\n",
      "              Limes       1.00      0.92      0.96       166\n",
      "             Lychee       0.94      1.00      0.97       166\n",
      "          Mandarine       1.00      1.00      1.00       166\n",
      "              Mango       1.00      1.00      1.00       166\n",
      "           Maracuja       1.00      0.95      0.97       166\n",
      " Melon Piel de Sapo       1.00      0.99      1.00       246\n",
      "           Mulberry       1.00      1.00      1.00       164\n",
      "          Nectarine       0.90      0.93      0.92       164\n",
      "             Orange       1.00      1.00      1.00       160\n",
      "             Papaya       1.00      1.00      1.00       164\n",
      "      Passion Fruit       1.00      1.00      1.00       166\n",
      "              Peach       0.86      1.00      0.92       164\n",
      "         Peach Flat       0.96      0.88      0.92       164\n",
      "               Pear       0.98      0.76      0.86       164\n",
      "         Pear Abate       1.00      0.94      0.97       166\n",
      "       Pear Monster       0.94      1.00      0.97       166\n",
      "      Pear Williams       1.00      0.96      0.98       166\n",
      "             Pepino       0.99      0.99      0.99       166\n",
      "           Physalis       1.00      1.00      1.00       164\n",
      " Physalis with Husk       1.00      0.84      0.91       164\n",
      "          Pineapple       0.94      1.00      0.97       166\n",
      "     Pineapple Mini       0.99      1.00      1.00       163\n",
      "       Pitahaya Red       0.97      0.94      0.96       166\n",
      "               Plum       0.98      0.97      0.98       151\n",
      "        Pomegranate       0.80      0.65      0.72       164\n",
      "             Quince       1.00      1.00      1.00       166\n",
      "           Rambutan       1.00      1.00      1.00       164\n",
      "          Raspberry       1.00      1.00      1.00       166\n",
      "              Salak       0.98      0.90      0.94       162\n",
      "         Strawberry       1.00      0.91      0.95       164\n",
      "   Strawberry Wedge       1.00      0.97      0.99       246\n",
      "          Tamarillo       1.00      1.00      1.00       166\n",
      "            Tangelo       1.00      1.00      1.00       166\n",
      "           Tomato 1       1.00      1.00      1.00       246\n",
      "           Tomato 2       1.00      0.52      0.68       225\n",
      "           Tomato 3       1.00      0.98      0.99       246\n",
      "           Tomato 4       0.58      1.00      0.74       160\n",
      "  Tomato Cherry Red       1.00      1.00      1.00       164\n",
      "      Tomato Maroon       1.00      1.00      1.00       127\n",
      "             Walnut       1.00      1.00      1.00       249\n",
      "\n",
      "           accuracy                           0.95     13877\n",
      "          macro avg       0.96      0.96      0.95     13877\n",
      "       weighted avg       0.96      0.95      0.95     13877\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "#Confusion matrix and classification report\n",
    "y_pred = model.predict_generator(validation_generator, nb_validation_samples // batch_size+1)\n",
    "y_pred = np.argmax(y_pred,axis=1)\n",
    "\n",
    "print('Confusion_matrix\\n\\n')\n",
    "\n",
    "cnf_matrix =confusion_matrix(validation_generator.classes, y_pred)\n",
    "print(cnf_matrix)\n",
    "\n",
    "print('classification_report')\n",
    "target_names = list(class_labels.values())\n",
    "\n",
    "print(classification_report(validation_generator.classes,y_pred,target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing our classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import re\n",
    "\n",
    "def draw_test(name, pred, im, true_label):\n",
    "    BLACK = [0,0,0]\n",
    "    expanded_image = cv2.copyMakeBorder(im, 160, 0, 0, 500 ,cv2.BORDER_CONSTANT,value=BLACK)\n",
    "    cv2.putText(expanded_image, \"predited - \"+ pred, (20, 60) , cv2.FONT_HERSHEY_SIMPLEX,1, (0,0,255), 2)\n",
    "    cv2.putText(expanded_image, \"true - \"+ true_label, (20, 120) , cv2.FONT_HERSHEY_SIMPLEX,1, (0,255,0), 2)\n",
    "    cv2.imshow(name, expanded_image)\n",
    "\n",
    "\n",
    "def getRandomImage(path, img_width, img_height):\n",
    "    \"\"\"function loads a random images from a random folder in our test path \"\"\"\n",
    "    folders = list(filter(lambda x: os.path.isdir(os.path.join(path, x)), os.listdir(path)))\n",
    "    random_directory = np.random.randint(0,len(folders))\n",
    "    path_class = folders[random_directory]\n",
    "    file_path = path + path_class\n",
    "    file_names = [f for f in listdir(file_path) if isfile(join(file_path, f))]\n",
    "    random_file_index = np.random.randint(0,len(file_names))\n",
    "    image_name = file_names[random_file_index]\n",
    "    final_path = file_path + \"/\" + image_name\n",
    "    return image.load_img(final_path, target_size = (img_width, img_height)), final_path, path_class\n",
    "\n",
    "# dimensions of our images\n",
    "img_width, img_height = 32, 32\n",
    "\n",
    "\n",
    "files = []\n",
    "predictions = []\n",
    "true_labels = []\n",
    "# predicting images\n",
    "for i in range(0, 10):\n",
    "    path = './fruits-360/validation/' \n",
    "    img, final_path, true_label = getRandomImage(path, img_width, img_height)\n",
    "    files.append(final_path)\n",
    "    true_labels.append(true_label)\n",
    "    x = image.img_to_array(img)\n",
    "    x = x * 1./255\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    images = np.vstack([x])\n",
    "    classes = np.argmax(model.predict(images, batch_size = 10),axis = 1)\n",
    "    predictions.append(classes)\n",
    "    \n",
    "for i in range(0, len(files)):\n",
    "    image = cv2.imread((files[i]))\n",
    "    draw_test(\"Prediction\", class_labels[predictions[i][0]], image, true_labels[i])\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: LF will be replaced by CRLF in CallBacks+Fruit_classifier/Fruit_classifier.ipynb.\n",
      "The file will have its original line endings in your working directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main 28099ac] 13:17/02-05-2021\n",
      " 1 file changed, 36 insertions(+), 3 deletions(-)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://github.com/sumit-mandal/DeepLearning-opencv_part2.git\n",
      " + 53a95d9...28099ac main -> main (forced update)\n"
     ]
    }
   ],
   "source": [
    "! git add Fruit_classifier.ipynb fruits_fresh_cnn.h5 fruit_classifier.pickle\n",
    "! git commit -m \"13:17/02-05-2021\"\n",
    "! git push -f origin main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cv] *",
   "language": "python",
   "name": "conda-env-cv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
